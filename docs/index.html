<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories">
  <meta property="og:title" content="DDAT"/>
  <meta property="og:description" content="Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories"/>
  <meta property="og:url" content="https://iconlab.negarmehr.com/DDAT/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/> -->


  <meta name="twitter:title" content="DDAT">
  <meta name="twitter:description" content="Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories">
  <!-- Path to banner image, should be in the path listed below. Optimal dimensions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Controls & Dynamics, Controls, Dynamics, Robot Learning, Diffusion Models, Robotics">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>DDAT</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} });
	  MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "AMS"} } });
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <style>
	.reference {
	   margin-bottom: 3mm;
	}
  </style>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories</h1>
		<div class="is-size-5 publication-authors"> <!-- Paper authors -->
              <span class="author-block"><a href="https://jean-baptistebouvier.github.io/" target="_blank">Jean-Baptiste Bouvier</a>,</span>
	      <span class="author-block"><a href="https://kh-ryu.github.io/" target="_blank">Kanghyun Ryu</a>,</span>
              <span class="author-block"><a href="https://kartik-nagpal.github.io/" target="_blank">Kartik Nagpal</a>,</span>
	      <span class="author-block"><a href="https://qiayuanl.github.io/" target="_blank">Qiayuan Liao</a>,</span>
	      <span class="author-block"><a href="https://hybrid-robotics.berkeley.edu/koushil/" target="_blank">Koushil Sreenath</a>,</span>
              <span class="author-block"><a href="https://negarmehr.com/" target="_blank">Negar Mehr</a></span><br>
		<a href="https://iconlab.negarmehr.com/" target="_blank">ICON Lab</a> at UC Berkeley <br>
		under review	<!--Robotics: Science and Systems (RSS) 2025-->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/25" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/labicon/DDAT/tree/main/code" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

		<!-- Blog Link -->
                <!--span class="link-block">
                  <a href="https://jean-baptistebouvier.github.io/assets/blog_posts/policed_RL/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
		    <i class="fas fa-scroll"></i>
                  </span>
                  <span>Blog</span>
                </a>
		</span-->
			    
            </div>
	</div>
        </div>
      </div>
    </div>
  </div>
</section>

 
            

                 




	
<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop width="852" height="480">
        <source src="videos/Hardware_comparison_480p.mp4" type="video/mp4">
      </video>
      <h4 class="subtitle has-text-centered">
        Unitree GO2 <em>zero-shot</em> hardware deployment of <em>open-loop</em> trajectories generated by a vanilla diffusion policy (left) and our DDAT model (right).<br>
        The vanilla diffusion policy fails at walking through the cones in open-loop. By accounting for the quadruped's dynamics our open-loop diffusion policy succeeds in following the corridor.
      </h4>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
        Diffusion models excel at creating images and videos thanks to their multimodal generative capabilities.
	These same capabilities have made diffusion models increasingly popular in robotics research, where they are extensively used for generating robot motion.
    	However, the stochastic nature of diffusion models is fundamentally at odds with the precise dynamical equations describing the feasible motion of robots.
	Hence, generating dynamically admissible robot trajectories is a challenge for diffusion models.
    	To alleviate this issue, we introduce <em>DDAT: <ins>D</ins>iffusion policies for <ins>D</ins>ynamically <ins>A</ins>missible <ins>T</ins>rajectories</em> to generate provably admissible trajectories of black-box robotic systems using diffusion models.
    	A sequence of states is a dynamically admissible trajectory if each state of the sequence belongs to the reachable set of its predecessor by the robot's equations of motion.
    	To generate such trajectories, our diffusion policies project their predictions onto a dynamically admissible manifold during both training and inference to align the objective of the denoiser neural network with the dynamical admissibility constraint. Due to the auto-regressive nature of such projections as well as the black-box nature of robot dynamics, trajectory projections are challenging.  
    	We thus enforce admissibility by iteratively sampling a polytopic under-approximation of the reachable set of a state onto which we project its predicted successor, before iterating this process with the projected successor.
    	By producing accurate trajectories, this projection eliminates the need for diffusion models to continually replan, enabling <em>one-shot long-horizon trajectory planning</em>.
    	We demonstrate that our proposed framework generates higher quality dynamically admissible robot trajectories through extensive simulations on a quadcopter and various MuJoCo environments, along with real-world experiments on a Unitree GO1 and GO2.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->





	
<section class="section hero is-small">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <img src="pictures/DDAT_scheme.svg" alt="DDAT illustration" style="height:300px !important; display:block !important; margin:auto !important;"/>
	<div class="content has-text-justified">
          <p>
         Schematic illustration of DDAT.
	 Diffusion model $D_\theta$ is trained to predict a trajectory <strong><span style="color:red;">$\tilde{\tau}$</span></strong> given a trajectory $\tau$
	 from the training dataset corrupted by noise $\varepsilon$.
	  If the noise level $\sigma$ of signal $\varepsilon$ is sufficiently small, $\mathcal{P}_\sigma$ projects <strong><span style="color:red;">$\tilde{\tau}$</span></strong>
	  to the dynamically admissible trajectory <strong><span style="color:green;">$\tau_p$</span></strong>.
	  The loss $\| <strong><span style="color:green;">$\tau_p$</span></strong> - \tau\|$ is used to update $D_\theta$.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop width="1120" height="480">
        <source src="videos/Hardware_GO1.mp4" type="video/mp4">
      </video>
      <h4 class="subtitle has-text-centered">
        Unitree GO1 <em>zero-shot</em> hardware deployment of an <em>open-loop</em> trajectory generated by a our DDAT model.
      </h4>
    </div>
  </div>
</section>


  
<!-- Image carousel -->
<section class="hero is-light">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="pictures/Hopper_SAE_500.svg" alt="Statewise admissibility error" style="height:400px !important; display:block !important; margin:auto !important;"/>
        <h4 class="subtitle has-text-centered">
          Statewise admissibility error over 500 Hopper trajectories. <br>
	The error <strong><span style="color:blue;">without projections</span></strong> is much larger than when using
	<strong><span style="color:orange;">projections at inference</span></strong> or
	<strong><span style="color:green;">training with projections</span></strong>. <br>
	All diffusion models generate only state trajectories.
        </h4>
      </div>
      <div class="item">
        <img src="pictures/Hopper_CAE_500.svg" alt="Cumulative admissibility error" style="height:400px !important; display:block !important; margin:auto !important;"/>
        <h4 class="subtitle has-text-centered">
           Cumulative admissibility error over 500 Hopper trajectories. <br>
	The error <strong><span style="color:blue;">without projections</span></strong> is much larger than when using
	<strong><span style="color:orange;">projections at inference</span></strong> or
	<strong><span style="color:green;">training with projections</span></strong>. <br>
	All diffusion models generate only state trajectories.
        </h4>
      </div>
     <div class="item">
      <img src="pictures/Walker_SAE_400.svg" alt="Statewise admissibility error" style="height:400px !important; display:block !important; margin:auto !important;"/>
      <h4 class="subtitle has-text-centered">
           Statewise admissibility error over 400 Walker trajectories. <br>
	The error <strong><span style="color:blue;">without projections</span></strong> is much larger than when using
	<strong><span style="color:orange;">projections at inference</span></strong>. <br>
	Our model <strong><span style="color:green;">trained with projections $\mathcal{P}^\text{SA}$</span></strong> has no error. <br>
	All diffusion models generate states and actions.
      </h4>
    </div>
    <div class="item">
      <img src="pictures/Walker_CAE_400.svg" alt="Cumulative admissibility error" style="height:400px !important; display:block !important; margin:auto !important;"/>
       <h4 class="subtitle has-text-centered">
           Cumulative admissibility error over 400 Walker trajectories. <br>
	The error <strong><span style="color:blue;">without projections</span></strong> is much larger than when using
	<strong><span style="color:orange;">projections at inference</span></strong>. <br>
	Our model <strong><span style="color:green;">trained with projections $\mathcal{P}^\text{SA}$</span></strong> has no error. <br>
	All diffusion models generate states and actions.
      </h4>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<section class="section hero is-small">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
	<div class="content has-text-justified">
            <p>
              We implement POLICEd RL on the KUKA arm and train it to reach a target while avoiding a constraint area, as illustrated above.
	      We use the classic RL algorithm Twin Delayed DDPG <a href="#TD3">(TD3)</a> with POLICEd layers.
	      We compare this POLICEd implementation against a TD3 baseline, a Constrained Policy Optimization <a href="#CPO">(CPO)</a> soft-constraint algorithm,
	      and a learned <a href="#yang2023model">PPO-Barrier</a> safety certificate.
            </p>
        </div>
          <img src="static/images/comparison.png" alt="" height="400px"/>
          <div class="content has-text-justified">
            <p>
              Metrics comparison for different methods based on a 500 episode deployment with the fully-trained policies on the safe arm task.
              The completion task only assess whether the target is eventually reached, even if the constraint is not respected.
	      The most significant metric is the average percentage of constraint satisfaction, which shows that only POLICEd RL guarantees constraint satisfaction. 
              For all metrics higher is better (&uarr;). 
            </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Presentation video-->
<!--section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
        <h2 class="title is-3">Video Presentation given at RSS 2024</h2>
          <div class="publication-video">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/xMWSqjRrcVc?si=Puj4cTJtLFcLGyH1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"   referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
        </div>
        </div>
      </div>
    </div>
  </div>
</section-->
	
<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!- - Paper video. - ->
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <!- - Youtube embed code here - ->
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!- - Your video file here - ->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!- - Your video file here - ->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!- - Your video file here - ->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!--section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <iframe  src="static/pdfs/RSS poster.pdf" width="100%" height="1100"></iframe>
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{bouvier2025ddat,
        title = {DDAT: Diffusion Policies Enforcing Dynamically Admissible Robot Trajectories},
        author = {Bouvier, Jean-Baptiste and Ryu, Kanghyun and Nagpal, Kartik and Mehr, Negar},
        booktitle = {Robotics: Science and Systems (RSS)},
        year = {2025}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!--References -->
<section class="section hero is-small">
  <div class="container is-max-desktop content">
    <h2 class="title">References</h2>
    <dl>
      <dt><strong>[CPO]</strong></dt>
	<dd>
	  <div class="reference" id="CPO">
	    Joshua Achiam, David Held, Aviv Tamar, and Pieter Abbeel,
	    <a href="https://proceedings.mlr.press/v70/achiam17a" target="_blank" rel="noopener noreferrer">Constrained Policy Optimization</a>,
	    34th International Conference on Machine Learning (ICML), 2017.
	  </div>
	</dd>
	<dt><strong>[POLICE]</strong></dt>
	<dd>
	  <div class="reference" id="POLICE">
	    Randall Balestriero and Yann LeCun,
	    <a href="https://ieeexplore.ieee.org/abstract/document/10096520" target="_blank" rel="noopener noreferrer"> POLICE: Provably optimal linear constraint enforcement for deep neural networks</a>,
	    IEEE International Conference on Acoustics, Speech and Signal Processing, 2023.
	  </div>
	</dd>
	<dt><strong>[TD3]</strong></dt>
	<dd>
	  <div class="reference" id="TD3">
	    Scott Fujimoto, Herke Hoof, and David Meger,
	    <a href="https://proceedings.mlr.press/v80/fujimoto18a.html" target="_blank" rel="noopener noreferrer">Addressing function approximation error in actor-critic methods</a>,
	    International Conference on Machine Learning (ICML), 2018.
	  </div>
	</dd>
	<dt><strong>[PPO-Barrier]</strong></dt>
	<dd>
	  <div class="reference" id="yang2023model">
	    Yujie Yang, Yuxuan Jiang, Yichen Liu, Jianyu Chen, and Shengbo Eben Li,
	    <a href="https://ieeexplore.ieee.org/document/10023989" target="_blank" rel="noopener noreferrer">Model-free safe reinforcement learning through neural barrier certificate</a>,
	    IEEE Robotics and Automation Letters, 2023.
	  </div>
	</dd>
    </dl>  
  </div>
</section>

	
	
<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This work is supported by the National Science Foundation, under grants ECCS-2145134, CAREER Award, CNS-2423130, and CCF-2423131. 
          </p>
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
